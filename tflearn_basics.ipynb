{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sunupi/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Get Data\n",
    "california_housing_dataframe = pd.read_csv(\"https://storage.googleapis.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index))\n",
    "california_housing_dataframe.describe()\n",
    "\n",
    "train_percent = 10 #@param\n",
    "train_size = int(california_housing_dataframe.shape[0]*(train_percent/100.0))\n",
    "test_size = california_housing_dataframe.shape[0] - train_size\n",
    "train_df = california_housing_dataframe.head(train_size)[:]\n",
    "test_df = california_housing_dataframe.tail(test_size)[:]\n",
    "\n",
    "del california_housing_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'median_house_value'\n",
    "feature_cols = ['total_rooms','total_bedrooms','population','households','median_income']\n",
    "\n",
    "train_x = train_df[feature_cols][:]\n",
    "train_y = train_df[target_col][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8545</th>\n",
       "      <td>6365.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>2767.0</td>\n",
       "      <td>1698.0</td>\n",
       "      <td>3.6451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>3030.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>4.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14184</th>\n",
       "      <td>2173.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>8.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>1248.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>3.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16902</th>\n",
       "      <td>3263.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>2.4708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_rooms  total_bedrooms  population  households  median_income\n",
       "8545        6365.0          1784.0      2767.0      1698.0         3.6451\n",
       "4445        3030.0           532.0      1668.0       509.0         4.6250\n",
       "14184       2173.0           349.0       891.0       345.0         8.0158\n",
       "4709        1248.0           322.0      1282.0       326.0         3.2031\n",
       "16902       3263.0           799.0      1384.0       578.0         2.4708"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m35453730816.00000\u001b[0m\u001b[0m | time: 0.034s\n",
      "| SGD | epoch: 010 | loss: 35453730816.00000 - R2: 0.1157 -- iter: 1664/1700\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m35030753280.00000\u001b[0m\u001b[0m | time: 1.040s\n",
      "| SGD | epoch: 010 | loss: 35030753280.00000 - R2: 0.1309 | val_loss: 32176790294.28706 - val_acc: 0.1645 -- iter: 1700/1700\n",
      "--\n",
      "INFO:tensorflow:/Users/sunupi/Projects/tf_overview/checkpoints/basic_dnn-140 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('\\nInput features:  ', [6365.0, 1784.0, 2767.0, 1698.0, 3.6451])\n",
      "\n",
      " Predicted output: 181604\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Regression data- 10 training instances\n",
    "#10 input features per instance.\n",
    "#X=np.random.rand(10,5).tolist()\n",
    "X = train_x.as_matrix().tolist()\n",
    "#2 output features per instance\n",
    "#Y = np.random.rand(10,1).tolist()\n",
    "Y = train_y.reshape([len(train_y),1]).tolist()\n",
    "\n",
    "# Multiple Regression graph, 10-d input layer\n",
    "input_ = tflearn.input_data(shape=[None,5])\n",
    "#10-d fully connected layer\n",
    "r1 = tflearn.fully_connected(input_,10)\n",
    "#2-d fully connected layer for output\n",
    "r1 = tflearn.fully_connected(r1,1)\n",
    "r1 = tflearn.regression(r1,\n",
    "                        optimizer='sgd',\n",
    "                        loss='mean_square',\n",
    "                        metric='R2',\n",
    "                        learning_rate=0.01,\n",
    "                        batch_size=12)\n",
    "\n",
    "m = tflearn.DNN(r1,\n",
    "                tensorboard_verbose=3,\n",
    "                tensorboard_dir=\"/tmp/logs/basic_dnn\",\n",
    "                checkpoint_path=\"/Users/sunupi/Projects/tf_overview/checkpoints/basic_dnn\")\n",
    "m.fit(X_inputs=X,\n",
    "      Y_targets=Y,\n",
    "      validation_set=[X,Y],\n",
    "      batch_size=128,\n",
    "      n_epoch=10,\n",
    "      show_metric=True,\n",
    "      snapshot_epoch=True,\n",
    "      run_id='basic_dnn')\n",
    "\n",
    "#Predict for 1 instance\n",
    "print(\"\\nInput features:  \",X[0])\n",
    "print(\"\\n Predicted output: %d\"%m.predict([X[0]])[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do not forget to reset the graph\n",
    "##### Run tensorboard --logdir='/tmp/logs/basic_dnn'\n",
    "##### Tensorboard http://0.0.0.0:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/Users/sunupi/Projects/tf_overview/basic_regressor_v1.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n",
      "WARNING:tensorflow:Error encountered when serializing data_augmentation.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'NoneType' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing data_preprocessing.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'NoneType' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing summary_tags.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'dict' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "m.save('basic_regressor_v1.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79.170074]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict([[1,2,3,4,5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets Create another graph and load a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:9: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Regression data- 10 training instances\n",
    "#10 input features per instance.\n",
    "#X=np.random.rand(10,5).tolist()\n",
    "X = train_x.as_matrix().tolist()\n",
    "#2 output features per instance\n",
    "#Y = np.random.rand(10,1).tolist()\n",
    "Y = train_y.reshape([len(train_y),1]).tolist()\n",
    "\n",
    "# Multiple Regression graph, 10-d input layer\n",
    "input_ = tflearn.input_data(shape=[None,5])\n",
    "#10-d fully connected layer\n",
    "r2 = tflearn.fully_connected(input_,10)\n",
    "#2-d fully connected layer for output\n",
    "r2 = tflearn.fully_connected(r2,1)\n",
    "r2 = tflearn.regression(r2,\n",
    "                        optimizer='sgd',\n",
    "                        loss='mean_square',\n",
    "                        metric='R2',\n",
    "                        learning_rate=0.01,\n",
    "                        batch_size=12)\n",
    "\n",
    "m2 = tflearn.DNN(r2,\n",
    "                 tensorboard_verbose=3,\n",
    "                 tensorboard_dir=\"/tmp/logs/basic_regressor\",\n",
    "                 checkpoint_path=\"/Users/sunupi/Projects/tf_overview/tflearn_checkpoints/cp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "cp-112.data-00000-of-00001\n",
      "cp-112.index\n",
      "cp-112.meta\n",
      "cp-126.data-00000-of-00001\n",
      "cp-126.index\n",
      "cp-126.meta\n",
      "cp-14.data-00000-of-00001\n",
      "cp-14.index\n",
      "cp-14.meta\n",
      "cp-140.data-00000-of-00001\n",
      "cp-140.index\n",
      "cp-140.meta\n",
      "cp-28.data-00000-of-00001\n",
      "cp-28.index\n",
      "cp-28.meta\n",
      "cp-42.data-00000-of-00001\n",
      "cp-42.index\n",
      "cp-42.meta\n",
      "cp-56.data-00000-of-00001\n",
      "cp-56.index\n",
      "cp-56.meta\n",
      "cp-70.data-00000-of-00001\n",
      "cp-70.index\n",
      "cp-70.meta\n",
      "cp-84.data-00000-of-00001\n",
      "cp-84.index\n",
      "cp-84.meta\n",
      "cp-98.data-00000-of-00001\n",
      "cp-98.index\n",
      "cp-98.meta\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls tflearn_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model prediction: 79.291\n",
      "Random weights prediction: -0.012\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunupi/Projects/tf_overview/tflearn_checkpoints/cp-14\n",
      "Random weights prediction: 0.926\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunupi/Projects/tf_overview/tflearn_checkpoints/cp-140\n",
      "Random weights prediction: 79.291\n"
     ]
    }
   ],
   "source": [
    "print 'Final model prediction: %.3f'%m.predict([[1,2,3,4,5]])\n",
    "print 'Random weights prediction: %.3f'%m2.predict([[1,2,3,4,5]])\n",
    "m2.load('tflearn_checkpoints/cp-14')\n",
    "print 'Random weights prediction: %.3f'%m2.predict([[1,2,3,4,5]])\n",
    "m2.load('tflearn_checkpoints/cp-140')\n",
    "print 'Random weights prediction: %.3f'%m2.predict([[1,2,3,4,5]])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
